{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_1kjL8wUTvAe"
   },
   "source": [
    "# **Multi-Objective Generative Adversarial Network with 3D Dataset**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TxpFKwDcTpqC"
   },
   "source": [
    "## Prepare necessary libraries and build dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "93OZswxKM-F-",
    "outputId": "47ba0d46-8851-4e8c-9144-b10e3cf502a9",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ================== IMPORT LIBRARIES ==================\n",
    "import os\n",
    "\n",
    "# This allow a silent import of Tensorflow\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import glob\n",
    "import time\n",
    "import json\n",
    "from statistics import mean\n",
    "from google_drive_downloader import GoogleDriveDownloader\n",
    "\n",
    "from IPython import display\n",
    "\n",
    "print(\"Successfully Load All Libraries - Tensorflow Version {}\".format(tf.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0LLrQsldk6dy",
    "outputId": "0fb77cbd-5fc6-49f2-8acc-24fe2c5168f6"
   },
   "outputs": [],
   "source": [
    "# ================= SET UP PARAMETERS ==================\n",
    "\n",
    "# The latent dimension of the generator network\n",
    "latent_dimension = 200\n",
    "\n",
    "# During the training, a number of samples using random latent values will be generated. This defines how many number of samples we want to generate\n",
    "num_examples_to_generate = 25\n",
    "\n",
    "# Epochs\n",
    "epochs = 3000\n",
    "\n",
    "# Batch size\n",
    "batch_size = 32\n",
    "\n",
    "# Learning rate\n",
    "generator_learning_rate = 1e-4\n",
    "realistic_discriminator_learning_rate = 1e-6\n",
    "\n",
    "# Path of the directory where all the Json files are saved. \n",
    "data_files_directory = './data/chair_voxel_dataset/'\n",
    "\n",
    "# Path of the directory where the pretrained weights of the stability auxiliary discriminator will be loaded from. \n",
    "stability_auxiliary_discriminator_load_location = './data/pretrained_models/chair_stability_auxiliary_discriminator/epoch_50'\n",
    "\n",
    "# Path of the directory where the pretrained weights of the aesthetic auxiliary discriminator will be loaded from. \n",
    "aesthetic_auxiliary_discriminator_load_location = './data/pretrained_models/chair_aesthetic_auxiliary_discriminator/epoch_50'\n",
    "\n",
    "# Path of the directory where the pretrained weights of the function auxiliary discriminator will be loaded from. \n",
    "function_auxiliary_discriminator_load_location = './data/pretrained_models/chair_function_auxiliary_discriminator/epoch_50'\n",
    "\n",
    "# Path of the directory where the trained weights of the network will be saved. \n",
    "mo_gan_save_directory = './mogan_train/saved_models/'\n",
    "\n",
    "# Create the directory to save the trained weights of the network. \n",
    "try:\n",
    "    os.makedirs(mo_gan_save_directory)\n",
    "except FileExistsError:\n",
    "    print(\"The directory to save trained network weights already exists\")\n",
    "\n",
    "# The path of log file that contains training information. \n",
    "mo_gan_training_log_location = './mogan_train/logs.txt'\n",
    "\n",
    "# Create a txt file to save losses during training\n",
    "try:\n",
    "    log_file = open(mo_gan_training_log_location, \"x\")\n",
    "    log_file.close()\n",
    "except FileExistsError:\n",
    "    print(\"Log file already exists\")\n",
    "    \n",
    "# During the training, a number of samples using random latent values will be generated. This defines where these generated samples will be saved\n",
    "directory_to_generated_samples = './mogan_train/samples/'\n",
    "\n",
    "try:\n",
    "    os.makedirs(directory_to_generated_samples)\n",
    "except FileExistsError:\n",
    "    print(\"The directory to save generated samples already exists\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OrjQdCcZXMLl"
   },
   "source": [
    "Download the dataset. \n",
    "Each file is a JSON file that contains information of the geometry we converted from the ShapeNet dataset and the related ratings. \n",
    "\n",
    "The JSON file should have following properties: \n",
    "\n",
    "*   \"geometry\":  a multi-dimension array to represent the geometry. \n",
    "*   \"voxel_size\": the size of each voxels (should always equal to 1 in the context of this notebook)\n",
    "*   \"scaling_factor_from_original\": the scaling factor we used to scale the original mesh to produce this geometry\n",
    "*   \"geometry_shape\": a list representing the shape of the geometry. (should always be [32, 32, 64] in the context of this notebook)\n",
    "\n",
    "Ratings in the JSON files are as following: \n",
    "\n",
    "If the geometry is not given one of the ratings, the properties will note null\n",
    "*   \"stability_rating\": the stability rating as a float from 0 to 1\n",
    "*   \"aesthetic_rating\": the aesthetic rating as an integer from 0 to 10\n",
    "*   \"function_rating\": the function rating as an integer from 0 to 10\n",
    "\n",
    "Although the aesthetic_rating and function_rating are from 0 to 10 in the dataset. They should be normalized for the training, including the pretrained network should also produce a normalized rating. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# If the directory exists and is not empty we presume the dataset is already on the local drive. \n",
    "# If not, we will download the dataset. \n",
    "\n",
    "download_dataset_from_google_drive = False\n",
    "\n",
    "if os.path.isdir(data_files_directory):\n",
    "    if not os.listdir(data_files_directory):\n",
    "        # Directory is empty\n",
    "        download_dataset_from_google_drive = True\n",
    "    else:    \n",
    "        # Directory is not empty\n",
    "        download_dataset_from_google_drive = False\n",
    "else:\n",
    "    # Given directory doesn't exist\n",
    "    download_dataset_from_google_drive = True\n",
    "    \n",
    "if download_dataset_from_google_drive:\n",
    "\n",
    "    # This will get download all the json files that contain geometry and rating information from google drive to the destination directory\n",
    "    GoogleDriveDownloader.download_file_from_google_drive(file_id='1DJzSfSWUDkAhuEfu706pm0riC6ho_5NS', \n",
    "                                                          dest_path=os.path.join(data_files_directory, 'chair_voxel_dataset.zip'),\n",
    "                                                          unzip=True)\n",
    "    data_files_directory = data_files_directory + 'chair_voxel_dataset/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all the json file paths from the unzippped directory. \n",
    "data_file_paths = glob.glob(data_files_directory + \"*.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_files_with_stability_rating = []\n",
    "data_files_with_aesthetic_rating = []\n",
    "data_files_with_function_rating = []\n",
    "\n",
    "for data_file in data_file_paths:\n",
    "    with open(data_file) as json_file:\n",
    "        dictionary = json.load(json_file)\n",
    "        if dictionary[\"stability_rating\"] != None:\n",
    "            data_files_with_stability_rating.append(data_file)\n",
    "        if dictionary[\"aesthetic_rating\"] != None:\n",
    "            data_files_with_aesthetic_rating.append(data_file)\n",
    "        if dictionary[\"function_rating\"] != None:\n",
    "            data_files_with_function_rating.append(data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"There are {} json files in total. \".format(len(data_file_paths)))\n",
    "print(\"There are {} files that have stability rating. \".format(len(data_files_with_stability_rating)))\n",
    "print(\"There are {} files that have aesthetic rating. \".format(len(data_files_with_aesthetic_rating)))\n",
    "print(\"There are {} files that have function rating. \".format(len(data_files_with_function_rating)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define how many samples will be used for training\n",
    "num_training_samples = 67  # 6777"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define several helper functions below that will facilitate building the tensorflow dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================= HELPER FUNCTIONS ===================\n",
    "# This function can preview a geometry data using matplot lib\n",
    "def preview_geometries(geometry_data, plot_threshold=0.25, stability_model=None, aesthetic_model=None, function_model=None, save_plot_as_png=False, path_to_save=None):\n",
    "    # geometry_data must be an array of shape [32, 32, 64, 1]\n",
    "    if stability_model is not None:\n",
    "        stability_prediction = np.array(stability_model(np.expand_dims(geometry_data, axis=0)))[0][0]\n",
    "    else:\n",
    "        stability_prediction = None\n",
    "    \n",
    "    if aesthetic_model is not None:\n",
    "        aesthetic_prediction = np.array(aesthetic_model(np.expand_dims(geometry_data, axis=0)))[0][0]\n",
    "    else:\n",
    "        aesthetic_prediction = None\n",
    "    \n",
    "    if function_model is not None:\n",
    "        function_prediction = np.array(function_model(np.expand_dims(geometry_data, axis=0)))[0][0]\n",
    "    else:\n",
    "        function_prediction = None\n",
    "    \n",
    "    generation_title = \"Stability Prediction is {}\\nAesthetic Prediction is {}\\nFunction Prediction is {}\".format(str(stability_prediction), str(aesthetic_prediction), str(function_prediction))\n",
    "\n",
    "    x = []\n",
    "    y = []\n",
    "    z = []\n",
    "\n",
    "    data = np.squeeze(geometry_data, axis=-1)\n",
    "    for i in range(0, len(data)):\n",
    "        for j in range(0, len(data[i])):\n",
    "            for k in range(0, len(data[i][j])):\n",
    "                if data[i][j][k] >= plot_threshold:\n",
    "                    x.append(i)\n",
    "                    y.append(j)\n",
    "                    z.append(k)\n",
    "\n",
    "    z_c = z\n",
    "\n",
    "    # We decided to plot the results with a gradient color map so the depth and geometries are clearer to see. \n",
    "    from matplotlib.colors import ListedColormap\n",
    "\n",
    "    N = 256\n",
    "    vals = np.ones((N, 4))\n",
    "    vals[:, 0] = np.linspace(1, 0, N)\n",
    "    vals[:, 1] = np.linspace(43/N, 43/N, N)\n",
    "    vals[:, 2] = np.linspace(82/N, 82/N, N)\n",
    "    custom_cmp = ListedColormap(vals)\n",
    "\n",
    "    fig = plt.figure(figsize=(5,5))\n",
    "    fig = plt.axes(projection='3d')\n",
    "    \n",
    "    # Data for three-dimensional scattered points\n",
    "    fig.scatter3D(np.array(x), np.array(y) * -1, np.array(z), cmap=custom_cmp, c=z_c)\n",
    "    fig.set_zlim(0,64)\n",
    "    fig.set_ylim(-64,0)\n",
    "    fig.set_xlim(0,64)\n",
    "    plt.title(generation_title);\n",
    "    if (save_plot_as_png):\n",
    "        plt.savefig(path_to_save + '.png')\n",
    "  \n",
    "    plt.show()\n",
    "    return plt\n",
    "\n",
    "# This function reads a custom dictionary data\n",
    "def read_json_file_geometry(filepath):\n",
    "    with open(filepath.numpy()) as json_file:\n",
    "        dictionary = json.load(json_file)\n",
    "\n",
    "    tensor = tf.convert_to_tensor(np.array(dictionary[\"geometry\"]), dtype=tf.float32)\n",
    "    tensor = tf.expand_dims(tensor, -1)\n",
    "    return tensor\n",
    "\n",
    "# Function to build dataset without labels\n",
    "def build_dataset_wo_labels(filepaths, batch_size):\n",
    "    file_list = tf.data.Dataset.list_files(filepaths)\n",
    "    ds = file_list.map(lambda x: tf.py_function(read_json_file_geometry, [x], Tout=tf.float32))\n",
    "    ds = ds.shuffle(4, reshuffle_each_iteration=True)\n",
    "    ds = ds.batch(batch_size)\n",
    "    ds = ds.prefetch(4)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build tensorflow dataset\n",
    "\n",
    "train_ds = build_dataset_wo_labels(data_file_paths[0:num_training_samples], batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can preview the first geometry in first batch as following\n",
    "\n",
    "for each_batch in train_ds:\n",
    "    preview_geometries(each_batch[0], plot_threshold=0.25, stability_model=None, aesthetic_model=None, function_model=None, save_plot_as_png=False, path_to_save=None)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load pretrained networks for multi-objective generative adversarial network training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build the multi-objective generative adversarial network. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9Xk5sOe1kLgo"
   },
   "outputs": [],
   "source": [
    "# ================ SET UP MACHINE LEARNING MODELS =========\n",
    "def make_generator_model():\n",
    "    model = tf.keras.Sequential()\n",
    "\n",
    "    #Layer 1 - Fully Connected: Take in noise vector, use dense and reshape to 2x2x4x512\n",
    "    model.add(tf.keras.layers.Dense(2*2*4*512, use_bias=False, input_shape=(latent_dimension,)))\n",
    "    model.add(tf.keras.layers.Reshape((2, 2, 4, 512)))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.ReLU())\n",
    "    assert model.output_shape == (None, 2, 2, 4, 512) \n",
    "\n",
    "    # Layer 2\n",
    "    model.add(tf.keras.layers.Conv3DTranspose(256, (4, 4, 4), strides=(2, 2, 2), padding='same'))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.ReLU())\n",
    "    assert model.output_shape == (None, 4, 4, 8, 256) \n",
    "    \n",
    "    # Layer 3\n",
    "    model.add(tf.keras.layers.Conv3DTranspose(128, (4,4,4), strides=(2, 2, 2), padding='same'))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.ReLU())\n",
    "    assert model.output_shape == (None, 8, 8, 16, 128)\n",
    "\n",
    "    # Layer 4\n",
    "    model.add(tf.keras.layers.Conv3DTranspose(64, (4, 4, 4), strides=(2, 2, 2), padding='same'))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.ReLU())\n",
    "    assert model.output_shape == (None, 16, 16, 32, 64)\n",
    "\n",
    "    # Layer 5\n",
    "    model.add(tf.keras.layers.Conv3DTranspose(1, (4, 4, 4), strides=(2, 2, 2), padding='same'))\n",
    "    assert model.output_shape == (None, 32, 32, 64, 1)\n",
    "    model.add(tf.keras.layers.Activation('tanh'))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_discriminator_model():\n",
    "    model = tf.keras.Sequential()\n",
    "\n",
    "    #Layer 1\n",
    "    model.add(tf.keras.layers.Conv3D(64, (4, 4, 4), strides=(2, 2, 2), padding='same', input_shape=(32, 32, 64, 1)))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.LeakyReLU(alpha = 0.2))\n",
    "    assert model.output_shape == (None, 16, 16, 32, 64)\n",
    "\n",
    "    #Layer 2\n",
    "    model.add(tf.keras.layers.Conv3D(128, (4, 4, 4), strides=(2, 2, 2), padding='same'))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.LeakyReLU(alpha =0.2 ))\n",
    "    assert model.output_shape == (None, 8, 8, 16, 128)\n",
    "\n",
    "    #Layer 3\n",
    "    model.add(tf.keras.layers.Conv3D(256, (4, 4, 4), strides=(2, 2, 2), padding='same'))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.LeakyReLU(alpha = 0.2))\n",
    "    assert model.output_shape == (None, 4, 4, 8, 256)\n",
    "\n",
    "    #Layer 4\n",
    "    model.add(tf.keras.layers.Conv3D(512, (4, 4, 4), strides=(2, 2, 2), padding='same'))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.LeakyReLU(alpha = 0.2))\n",
    "    assert model.output_shape == (None, 2, 2, 4, 512)\n",
    "\n",
    "    #Layer 6 Flatten and Dense\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    model.add(tf.keras.layers.Dense(1))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = make_generator_model()\n",
    "realistic_discriminator = make_discriminator_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to make sure the networks are set up correctly. \n",
    "\n",
    "Use random latent dimension values to generate a geometry and use the discriminator to make a prediction. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "efZdWp61iKDl",
    "outputId": "eefd6a13-2ca6-4006-f1c2-101c4f87c5e5"
   },
   "outputs": [],
   "source": [
    "generated_geometry = generator(np.random.rand(1, latent_dimension))\n",
    "realistic_discriminator(generated_geometry)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build the stability auxiliary discriminator network and load the pretrained weights.\n",
    "\n",
    "The weights to load must match structure as the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stability_auxiliary_discriminator_model = tf.keras.Sequential(\n",
    "  [\n",
    "    tf.keras.layers.Conv3D(16, (4, 4, 4), strides=(2, 2, 2), padding='same', input_shape=(32, 32, 64, 1)), \n",
    "    tf.keras.layers.LeakyReLU(), \n",
    "    tf.keras.layers.Dropout(0.3), \n",
    "\n",
    "    tf.keras.layers.Conv3D(32, (4, 4, 4), strides=(2, 2, 2), padding='same'), \n",
    "    tf.keras.layers.LeakyReLU(), \n",
    "    tf.keras.layers.Dropout(0.3), \n",
    "\n",
    "    tf.keras.layers.Conv3D(64, (4, 4, 4), strides=(2, 2, 2), padding='same'), \n",
    "    tf.keras.layers.LeakyReLU(), \n",
    "    tf.keras.layers.Dropout(0.3), \n",
    "\n",
    "    tf.keras.layers.Conv3D(128, (4, 4, 4), strides=(2, 2, 2), padding='same'), \n",
    "    tf.keras.layers.LeakyReLU(), \n",
    "    tf.keras.layers.Dropout(0.3), \n",
    "\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(1), \n",
    "  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    stability_auxiliary_discriminator_model.load_weights(stability_auxiliary_discriminator_load_location)\n",
    "    \n",
    "# If the pretrained weights cannot be loaded from the directory, we download the weights from google drive trained by researchers. \n",
    "except:\n",
    "    GoogleDriveDownloader.download_file_from_google_drive(file_id='1bDwYinD8Tshf0GqnV-ktgRS8hDCUb1oZ', \n",
    "                                                          dest_path='./data/pretrained_models/chair_stability_auxiliary_discriminator.zip',\n",
    "                                                          unzip=True)\n",
    "    stability_auxiliary_discriminator_model.load_weights('./data/pretrained_models/chair_stability_auxiliary_discriminator/epoch_50')\n",
    "\n",
    "print(\"Successfully loaded stability auxiliary discriminator weights\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build the aesthetic auxiliary discriminator network and load the pretrained weights.\n",
    "\n",
    "The weights to load must match structure as the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aesthetic_auxiliary_discriminator_model = tf.keras.Sequential(\n",
    "  [\n",
    "    tf.keras.layers.Conv3D(16, (4, 4, 4), strides=(2, 2, 2), padding='same', input_shape=(32, 32, 64, 1)), \n",
    "    tf.keras.layers.LeakyReLU(), \n",
    "    tf.keras.layers.Dropout(0.3), \n",
    "\n",
    "    tf.keras.layers.Conv3D(32, (4, 4, 4), strides=(2, 2, 2), padding='same'), \n",
    "    tf.keras.layers.LeakyReLU(), \n",
    "    tf.keras.layers.Dropout(0.3), \n",
    "\n",
    "    tf.keras.layers.Conv3D(64, (4, 4, 4), strides=(2, 2, 2), padding='same'), \n",
    "    tf.keras.layers.LeakyReLU(), \n",
    "    tf.keras.layers.Dropout(0.3), \n",
    "\n",
    "    tf.keras.layers.Conv3D(128, (4, 4, 4), strides=(2, 2, 2), padding='same'), \n",
    "    tf.keras.layers.LeakyReLU(), \n",
    "    tf.keras.layers.Dropout(0.3), \n",
    "\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(1), \n",
    "  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    aesthetic_auxiliary_discriminator_model.load_weights(aesthetic_auxiliary_discriminator_load_location)\n",
    "    \n",
    "# If the pretrained weights cannot be loaded from the directory, we download the weights from google drive trained by researchers. \n",
    "except:\n",
    "    GoogleDriveDownloader.download_file_from_google_drive(file_id='1clRiK4mjHAi8jwR0F84HzEebtkhrryfA', \n",
    "                                                          dest_path='./data/pretrained_models/chair_aesthetic_auxiliary_discriminator.zip',\n",
    "                                                          unzip=True)\n",
    "    aesthetic_auxiliary_discriminator_model.load_weights('./data/pretrained_models/chair_aesthetic_auxiliary_discriminator/epoch_50')\n",
    "    \n",
    "print(\"Successfully loaded aesthetic auxiliary discriminator weights\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build the function auxiliary discriminator network and load the pretrained weights.\n",
    "\n",
    "The weights to load must match structure as the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function_auxiliary_discriminator_model = tf.keras.Sequential(\n",
    "  [\n",
    "    tf.keras.layers.Conv3D(16, (4, 4, 4), strides=(2, 2, 2), padding='same', input_shape=(32, 32, 64, 1)), \n",
    "    tf.keras.layers.LeakyReLU(), \n",
    "    tf.keras.layers.Dropout(0.3), \n",
    "   \n",
    "    tf.keras.layers.Conv3D(32, (4, 4, 4), strides=(2, 2, 2), padding='same'), \n",
    "    tf.keras.layers.LeakyReLU(), \n",
    "    tf.keras.layers.Dropout(0.3), \n",
    "   \n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(1), \n",
    "  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    function_auxiliary_discriminator_model.load_weights(function_auxiliary_discriminator_load_location)\n",
    "    \n",
    "# If the pretrained weights cannot be loaded from the directory, we download the weights from google drive trained by researchers. \n",
    "except:\n",
    "    GoogleDriveDownloader.download_file_from_google_drive(file_id='1v2r9nfhA6HqHFZZ0xZ2W7u5X2pNF2eLp', \n",
    "                                                          dest_path='./data/pretrained_models/chair_function_auxiliary_discriminator.zip',\n",
    "                                                          unzip=True)\n",
    "    function_auxiliary_discriminator_model.load_weights('./data/pretrained_models/chair_function_auxiliary_discriminator/epoch_50')\n",
    "    \n",
    "print(\"Successfully loaded function auxiliary discriminator weights\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the multi-objective generative adversarial network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the expectations for each category (the values are normalized)\n",
    "\n",
    "Define the LAMBDA value (the weight) of each category, including the realistic adversarial network\n",
    "\n",
    "Because these weights are relative to each other, it is recommended to experimente with these numbers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_realistic_discriminator = True  # use the realistic discriminator during MOGAN training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stability_expectation = 0.05\n",
    "aesthetic_expectation = 0.05\n",
    "function_expectation = 0.85"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LAMBDA_realistic = 1.5\n",
    "LAMBDA_obj = [1, 1, 1]  # [stability, aesthetic, function, realistic]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_file = open(mo_gan_training_log_location, \"w\")\n",
    "log_file.write(\"Expectation Values for [stability, aesthetic, function]: {}\".format([stability_expectation, aesthetic_expectation, function_expectation]))\n",
    "log_file.write('\\n')\n",
    "log_file.write(\"Lambda Values for [stability, aesthetic, function, realistic]: {}\".format(LAMBDA_obj))\n",
    "log_file.write('\\n')\n",
    "log_file.write(\"Learning Rate for generator training: {}\".format(generator_learning_rate))\n",
    "log_file.write('\\n')\n",
    "log_file.write(\"Learning Rate for realistic discriminator training: {}\".format(realistic_discriminator_learning_rate))\n",
    "log_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the loss functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_real_loss(real_output, fake_output):\n",
    "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
    "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
    "    total_loss = real_loss + fake_loss\n",
    "    return total_loss, real_loss, fake_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_loss(generated_output, discriminator_label_obj, LAMBDA_obj, expectation_label_obj):\n",
    "    \n",
    "    generator_loss = cross_entropy(tf.ones_like(generated_output), generated_output)\n",
    "\n",
    "    # objective discriminator loss using mean absolute error\n",
    "    discriminator_obj_loss = tf.reduce_mean(tf.abs(discriminator_label_obj - expectation_label_obj), axis=0)\n",
    "\n",
    "    if len(LAMBDA_obj) == 1:\n",
    "        weighted_discriminator_obj_loss = LAMBDA_obj[0] * discriminator_obj_loss\n",
    "    else:\n",
    "        weighted_discriminator_obj_loss = tf.math.reduce_sum(tf.math.multiply(tf.cast(LAMBDA_obj, tf.float32), discriminator_obj_loss))\n",
    "\n",
    "    weighted_disc_obj_losses_as_tensor = tf.math.multiply(tf.cast(LAMBDA_obj, tf.float32), discriminator_obj_loss)\n",
    "    obj_1_loss = tf.math.reduce_mean(discriminator_obj_loss[0])\n",
    "    obj_2_loss = tf.math.reduce_mean(discriminator_obj_loss[1])\n",
    "    obj_3_loss = tf.math.reduce_mean(discriminator_obj_loss[2])\n",
    "    \n",
    "    if use_realistic_discriminator: \n",
    "        total_generator_loss = generator_loss * LAMBDA_realistic + weighted_discriminator_obj_loss\n",
    "        return weighted_discriminator_obj_loss, obj_1_loss, obj_2_loss, obj_3_loss\n",
    "    else:\n",
    "        return total_generator_loss, obj_1_loss, obj_2_loss, obj_3_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def mo_gan_train_step(geometries):\n",
    "    noise = tf.random.normal([batch_size, latent_dimension])\n",
    "\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "        # Generator output\n",
    "        generated_geometry = generator(noise, training=True)\n",
    "      \n",
    "        # Discriminator output\n",
    "        real_output = realistic_discriminator(geometries, training=True)\n",
    "        fake_output = realistic_discriminator(generated_geometry, training=True)\n",
    "      \n",
    "        # Loss functions\n",
    "        objective_stability = stability_auxiliary_discriminator_model(generated_geometry)\n",
    "        expectation_stability = tf.ones_like(objective_stability) * stability_expectation\n",
    "        objective_aesthetic = aesthetic_auxiliary_discriminator_model(generated_geometry)\n",
    "        expectation_aesthetic = tf.ones_like(objective_aesthetic) * aesthetic_expectation\n",
    "        objective_function = function_auxiliary_discriminator_model(generated_geometry)\n",
    "        expectation_function = tf.ones_like(objective_function) * function_expectation\n",
    "      \n",
    "        objective_list = tf.concat([objective_stability, objective_aesthetic, objective_function], axis=-1)\n",
    "        expectation_list = tf.concat([expectation_stability, expectation_aesthetic, expectation_function], axis=-1)\n",
    "\n",
    "        gen_loss, loss_obj_stability, loss_obj_aesthetic, loss_obj_function = generator_loss(fake_output, objective_list, LAMBDA_obj, expectation_list)\n",
    "        \n",
    "        if use_realistic_discriminator:\n",
    "            disc_loss, real_loss, fake_loss = discriminator_real_loss(real_output, fake_output)\n",
    "    \n",
    "    # Gradients\n",
    "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
    "    if use_realistic_discriminator:\n",
    "        gradients_of_discriminator = disc_tape.gradient(disc_loss, realistic_discriminator.trainable_variables)\n",
    "\n",
    "    # Update both networks\n",
    "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
    "    if use_realistic_discriminator:\n",
    "        realistic_discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, realistic_discriminator.trainable_variables))\n",
    "\n",
    "    if use_realistic_discriminator:\n",
    "        return gen_loss, disc_loss, loss_obj_stability, loss_obj_aesthetic, loss_obj_function\n",
    "    else:\n",
    "        return gen_loss, 0., loss_obj_stability, loss_obj_aesthetic, loss_obj_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Optimizers ----\n",
    "generator_optimizer = tf.keras.optimizers.Adam(generator_learning_rate)\n",
    "realistic_discriminator_optimizer = tf.keras.optimizers.Adam(realistic_discriminator_learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_sample_json(model, noise_input, directory_to_write, filename_to_write):\n",
    "    predictions = model(noise_input)\n",
    "    for i in range(predictions.shape[0]): # each num_examples_to_generate\n",
    "        # Create the information to write\n",
    "        dictionary_to_write = {\n",
    "            \"geometry\" : np.array(predictions[i], dtype=np.float64).tolist(),\n",
    "            \"voxel_size\" : 1,\n",
    "            \"scaling_factor_from_original\" : None,\n",
    "            \"geometry_shape\" : [32, 32, 64],\n",
    "\n",
    "            # Could also include the discriminator predictions\n",
    "            \"stability_discriminator_prediction\": np.array(stability_auxiliary_discriminator_model(tf.expand_dims(predictions[i], axis=0)), dtype=np.float64)[0][0],\n",
    "            \"aesthetic_discriminator_prediction\": np.array(aesthetic_auxiliary_discriminator_model(tf.expand_dims(predictions[i], axis=0)), dtype=np.float64)[0][0], \n",
    "            \"function_discriminator_prediction\": np.array(function_auxiliary_discriminator_model(tf.expand_dims(predictions[i], axis=0)), dtype=np.float64)[0][0]\n",
    "        }\n",
    "        # we write dataset for each txt file\n",
    "        with open(directory_to_write + filename_to_write + \"_prediction_\" + str(i) + \".json\", 'w', encoding='utf-8') as f:\n",
    "            json.dump(dictionary_to_write, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mo_gan_train(train_dataset, epochs):\n",
    "    \n",
    "    noise_vector = tf.random.normal([num_examples_to_generate, latent_dimension], seed=101)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        train_start = time.time()\n",
    "        \n",
    "        train_loss_generator = 0\n",
    "        train_loss_realistic_discriminator = 0\n",
    "        train_obj_1_losses = 0\n",
    "        train_obj_2_losses = 0\n",
    "        train_obj_3_losses = 0\n",
    "        train_iters = 0\n",
    "        \n",
    "        for each_batch in train_dataset:\n",
    "            loss_gen_loss, loss_disc_real, train_obj_1_loss, train_obj_2_loss, train_obj_3_loss = mo_gan_train_step(each_batch)\n",
    "            train_obj_1_losses += train_obj_1_loss\n",
    "            train_obj_2_losses += train_obj_2_loss\n",
    "            train_obj_3_losses += train_obj_3_loss\n",
    "            train_loss_generator += loss_gen_loss\n",
    "            train_loss_realistic_discriminator += loss_disc_real\n",
    "            train_iters += 1\n",
    "            if train_iters == int(num_training_samples/batch_size):\n",
    "                break\n",
    "        \n",
    "        log_file = open(mo_gan_training_log_location, \"a\")\n",
    "        log_file.write('\\n')\n",
    "        log_file.write('\\n')\n",
    "        log_file.write(\"Epoch: \" + str(epoch))\n",
    "        log_file.write('\\n')\n",
    "        log_file.write(\"Generator training loss: {:0.5f}\".format(train_loss_generator/train_iters))\n",
    "        log_file.write('\\n')\n",
    "        log_file.write(\"Realistic discriminator training loss: {:0.5f}\".format(train_loss_realistic_discriminator/train_iters))\n",
    "        log_file.write('\\n')\n",
    "        log_file.write(\"Objective stability training loss: {:0.5f}\".format(train_obj_1_losses/train_iters))\n",
    "        log_file.write('\\n')\n",
    "        log_file.write(\"Objective aesthetic training loss: {:0.5f}\".format(train_obj_2_losses/train_iters))\n",
    "        log_file.write('\\n')\n",
    "        log_file.write(\"Objective function training loss: {:0.5f}\".format(train_obj_3_losses/train_iters))\n",
    "        log_file.close()\n",
    "\n",
    "        write_sample_json(generator, noise_vector, directory_to_generated_samples, \"epoch_\" + str(epoch))\n",
    "        \n",
    "        display.clear_output(wait=False)\n",
    "        \n",
    "        print(\"Generated output: \")\n",
    "        # Here we preview the geometry generated from the first of the noise vectors\n",
    "        generated_geometry = np.squeeze(generator(np.expand_dims(noise_vector[0], axis=0)), axis=0)\n",
    "        preview_geometries(generated_geometry, plot_threshold=0.25, stability_model=stability_auxiliary_discriminator_model, aesthetic_model=aesthetic_auxiliary_discriminator_model, function_model=function_auxiliary_discriminator_model)\n",
    "        \n",
    "        print('Epoch: {}, Generator training Loss: {:0.5f}, Realistic discriminator training loss: {:0.5f}, Time: {:0.1f}'.format(epoch, train_loss_generator/train_iters, train_loss_realistic_discriminator/train_iters, time.time() - train_start))\n",
    "\n",
    "        # For every 10 epochs, we save the network weights\n",
    "        if epoch % 10 == 0:\n",
    "            generator.save_weights(mo_gan_save_directory + 'mo_vae_epoch_{}'.format(epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# mo_gan_train(train_ds, epochs)\n",
    "mo_gan_train(train_ds, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "jna2p9QAUWM6",
    "pTegEa4k1RXi"
   ],
   "machine_shape": "hm",
   "name": "210611 - MO_VAE.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
